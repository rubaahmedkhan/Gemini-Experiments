{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq7nTmXBwbhts89R60h7sZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubaahmedkhan/Gemini-Experiments/blob/main/langchain1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Gemini API with LangChain Project**\n"
      ],
      "metadata": {
        "id": "VsQgXPhLYSPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Required Package**\n",
        "**LangChain:** A framework for building applications using large language models, facilitating the creation of language model pipelines.\n",
        "\n",
        "**LangChain Google GenAI Integration**: An integration with Google's Generative AI tools, allowing for the use of advanced language models within the LangChain framework."
      ],
      "metadata": {
        "id": "wy-2bdrPYcOm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vnZUPBmqS5yJ"
      },
      "outputs": [],
      "source": [
        "# Install the LangChain and LangChain's Google GenAI integration\n",
        "# `-q` keeps the output minimal.\n",
        "# `-U` ensures you are using the latest versions of the package\n",
        "\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install -qU langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_google_genai as genai"
      ],
      "metadata": {
        "id": "3GZr1JKRTar3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ],
      "metadata": {
        "id": "eugFB6I8VGbb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "zs9NCGyRTkmY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "62R28HC_UAq6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Invocation**"
      ],
      "metadata": {
        "id": "cJE54LIVdXc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to urdu. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = mode.invoke(messages)\n",
        "ai_msg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLB-6v6pb56W",
        "outputId": "18feb757-397a-4a15-ed82-070252cfeb0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='مجھے پروگرامنگ سے بہت پیار ہے۔ (mujhay programming say bohat pyar hai)', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-3cb33a5d-20cf-4234-8d1f-dbb4882d8410-0', usage_metadata={'input_tokens': 20, 'output_tokens': 25, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPB0IYoKcd1L",
        "outputId": "3b9351c8-6b0e-451c-b13f-a28b8eb531ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مجھے پروگرامنگ سے بہت پیار ہے۔ (mujhay programming say bohat pyar hai)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chaining**\n",
        "We can chain our model with a prompt template like so:\n",
        "\n"
      ],
      "metadata": {
        "id": "MGR3pDLsV1CD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"input_language\": \"English\",\n",
        "        \"output_language\": \"German\",\n",
        "        \"input\": \"I love programming.\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "yt52UOOod6G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "ai_msg = mode.invoke(messages)\n",
        "ai_msg\n",
        "\n",
        "chain = prompt | mode\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"input_language\": \"urdu\",\n",
        "        \"output_language\": \"english\",\n",
        "        \"input\": \"mujhy nehari pasamd hai\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReoEnkxnd9Xn",
        "outputId": "e3e1c3d7-b1b8-481e-9891-54e27457b326"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='I like Nihari.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-44d0a013-e63e-4bbc-95e1-aec478d451cf-0', usage_metadata={'input_tokens': 19, 'output_tokens': 6, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image input:**"
      ],
      "metadata": {
        "id": "f1xO_4cPjPoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import httpx\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"describe the weather in this image\"},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "ai_msg = mode.invoke([message])\n",
        "ai_msg.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HtVwT9Idi8lP",
        "outputId": "6e953a9c-2131-49e3-eef4-d4e976a8e33e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The weather in the image appears to be sunny and clear.  The sky is mostly blue with a few scattered, wispy clouds.  The sunlight seems bright enough to cast shadows, although there aren't any strong shadows visible in the image, suggesting the sun might be relatively high in the sky. The overall impression is of a pleasant, warm day.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\"system\", \"Translate the user sentence to urdu.\"),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "mode.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1asluw4ykJNl",
        "outputId": "6be09c10-a9bd-4652-d008-3ae4c2522b9b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='مجھے پروگرامنگ بہت پسند ہے۔ (mujhe programming bohat pasand hai)', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8732fa5f-0bdf-4eea-b2c6-44c94f2e1c8c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stream:**"
      ],
      "metadata": {
        "id": "H0BrxehynS3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in mode.stream(messages):\n",
        "    #print(chunk)\n",
        "    print(chunk.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoYFmmn4kcWG",
        "outputId": "bd09b298-b6ab-424a-e200-91fbd23a65a8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مج\n",
            "ھے پروگرامنگ بہت پسند ہے۔ (mujhe programming\n",
            " bohat pasand hai)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream = mode.stream(messages)\n",
        "full = next(stream)\n",
        "for chunk in stream:\n",
        "    full += chunk\n",
        "full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi1ZlOA4kuRx",
        "outputId": "bcb58ba8-8e96-4fa3-88cf-77cecc348a92"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessageChunk(content=\"J'aime la programmation.\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'finish_reason': 'STOP'}, id='run-29ee4187-eda7-4a2e-aa6b-8fe9bab79804', usage_metadata={'input_tokens': 11, 'output_tokens': 7, 'total_tokens': 18, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}