{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwfjWqaN10mcpIGh91kPCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubaahmedkhan/Gemini-Experiments/blob/main/vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explore vision capabilities with the Gemini API**"
      ],
      "metadata": {
        "id": "jPrVmRjQyJYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you use the File API, you need to install the Gemini API SDK package and configure an API key. This section describes how to complete these setup steps."
      ],
      "metadata": {
        "id": "ldzyNDvm03YY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Insall the python SDK and import Pakages**"
      ],
      "metadata": {
        "id": "GqoLEkOm1Nh2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP_UXyyXv3bP",
        "outputId": "f03cbeda-c3d1-4a4a-f7fb-0a01ccaaa8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary packages.\n",
        "\n"
      ],
      "metadata": {
        "id": "a1u4j4UK2BE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "669Rb9XR2EKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up your API key**"
      ],
      "metadata": {
        "id": "ojGdn-Hi2Qs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "tKnw09VEwSkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai"
      ],
      "metadata": {
        "id": "mxHiPVHFwYb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client()\n"
      ],
      "metadata": {
        "id": "JK1k1FwdwfXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-X6XcRW2kC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting with images**\n",
        "\n"
      ],
      "metadata": {
        "id": "qEwbgUyQ2lQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Base64 encoded images**"
      ],
      "metadata": {
        "id": "qoTi15yV3YZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can upload public image URLs by encoding them as Base64 payloads. You can use the httpx library to fetch the image URLs. The following code example shows how to do this:\n",
        "\n"
      ],
      "metadata": {
        "id": "smuN_Zp53mEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "import base64\n",
        "\n",
        "# Retrieve an image\n",
        "image_path = \"https://www.opportunitiescircle.com/wp-content/uploads/2024/12/Generative-AI-for-Everyone-Free-Course-2025.jpg\"\n",
        "image = httpx.get(image_path)\n",
        "\n",
        "# Choose a Gemini model\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Create a prompt\n",
        "prompt = \"Caption this image.\"\n",
        "response = model.generate_content(\n",
        "    [\n",
        "        {\n",
        "            \"mime_type\": \"image/jpeg\",\n",
        "            \"data\": base64.b64encode(image.content).decode(\"utf-8\"),\n",
        "        },\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(\">\" + response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "kF8RYMCM4Fk6",
        "outputId": "8edcd095-443b-4477-9122-c214ebaa138f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Here's a caption for the image:\n\n**Option 1 (Concise):**\n\n> Learn Generative AI for FREE in 2025! This fully funded course is open to all countries, with no deadline.  [Link to website] #generativeAI #freeCourse #AICourse #DeepLearning\n\n\n**Option 2 (More detailed):**\n\n> Level up your AI skills with this fully funded Generative AI course, brought to you by DeepLearning.AI and Opportunities Circle!  No application deadline – learn at your own pace. Open to participants worldwide.  Enroll now! [Link to website] #AI #GenerativeAI #FreeEducation #OnlineCourse\n\n\n**Option 3 (Focus on urgency/scarcity - even though there's no deadline):**\n\n> Don't miss out on this incredible opportunity!  A completely FREE, fully funded Generative AI course is now available to everyone, regardless of location. Learn the skills of the future – enroll today! [Link to website] #AICourse #FreeLearning #GenerativeAI #LimitedTimeOffer (although not technically limited time)\n\n\n**Remember to replace \"[Link to website]\" with the actual URL from the image.** Choose the option that best suits your target audience and platform.\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiple images**"
      ],
      "metadata": {
        "id": "NH5261C95gJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prompt with multiple images in Base64 encoded format, you can do the following:"
      ],
      "metadata": {
        "id": "kmrT_oFl5pyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "import base64\n",
        "\n",
        "# Retrieve two images\n",
        "image_path_1 = \"https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSg1y2smnVz6-RMLN8eL2Tef1VakEV8U08StG2NNt7yZD1n6hPI\"\n",
        "image_path_2 = \"https://images.olx.com.pk/thumbnails/279059287-240x180.jpeg\"\n",
        "\n",
        "image_1 = httpx.get(image_path_1)\n",
        "image_2 = httpx.get(image_path_2)\n",
        "\n",
        "# Create a prompt\n",
        "prompt = \"Generate a list of all the objects contained in both images.\"\n",
        "\n",
        "response = model.generate_content([\n",
        "{'mime_type':'image/jpeg', 'data': base64.b64encode(image_1.content).decode('utf-8')},\n",
        "{'mime_type':'image/jpeg', 'data': base64.b64encode(image_2.content).decode('utf-8')}, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "KvUTtm3G5xlX",
        "outputId": "2efee18b-1872-44e8-c378-ab5000108fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a list of the objects or concepts present in both images:\n\n* **Machine Learning:** This is explicitly mentioned in both images as a core component of AI and a subject of study.\n\n* **Deep Learning:**  Also explicitly named in both;  the first image identifies it as a part of AI, and the second shows it as a learning component alongside machine learning.\n\n* **Python:**  Appears in the second image as a programming language used in AI/ML related studies.  While not explicitly named in the first image, Python is a very common language used in the AI fields described there, implying its presence implicitly.\n\n* **Data (implicitly):**  Both images strongly imply the importance of data. The first image discusses AI components dealing with data (machine learning, computer vision), and the second explicitly mentions \"Data Visualization\" and \"Data Science.\"\n\n\nIt is important to note that the other items mentioned in the images (Neural Networks, Natural Language Processing, Computer Vision, Data Structures, OOP, etc.) are either components *of* the above items or closely related concepts within the broader field of AI.  They don't appear as explicit commonalities across both images in the same way as the ones listed above.\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Upload one or more locally stored image files**"
      ],
      "metadata": {
        "id": "0gphAgWs617X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can upload one or more locally stored image files..\n",
        "\n",
        "You can download and First, save these files to your local directory.\n",
        "\n",
        "Then click Files on the left sidebar. For each file, click the Upload button, then navigate to that file's location and upload it:"
      ],
      "metadata": {
        "id": "heL-55GZ7HwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "sample_file_2 = PIL.Image.open('demo1.jpeg')\n",
        "sample_file_3 = PIL.Image.open('demo2.webp')"
      ],
      "metadata": {
        "id": "bXP5xWEZ61uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Create a prompt.\n",
        "prompt = \"what sees in both images explain in two lines\"\n",
        "\n",
        "response = model.generate_content([sample_file_2, sample_file_3, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "bXZS94kK8_Yg",
        "outputId": "27275de4-ec24-4607-d154-883ace9ae3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Both images relate to machine learning. The first is an advertisement for tutoring services, while the second is a cheat sheet summarizing various machine learning algorithms categorized by learning style."
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Large image payloads**"
      ],
      "metadata": {
        "id": "NICyQdG29keg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload an image file using the File API**"
      ],
      "metadata": {
        "id": "tX806dqk9pPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o jetpack.jpg https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhgN0iRm9yYy",
        "outputId": "81083682-b7b4-4595-e67d-e927badb7d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  349k  100  349k    0     0  2015k      0 --:--:-- --:--:-- --:--:-- 2018k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file and print a confirmation.\n",
        "sample_file = genai.upload_file(path=\"jetpack.jpg\",\n",
        "                            display_name=\"Jetpack drawing\")\n",
        "\n",
        "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK0j-RrF-AJ4",
        "outputId": "5f41ee69-839e-40ab-d68b-ad429b9a0450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'Jetpack drawing' as: https://generativelanguage.googleapis.com/v1beta/files/ui7oqyac3jl9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = genai.get_file(name=sample_file.name)\n",
        "print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3GqZnf--Z6n",
        "outputId": "2f88b990-f4e8-4ff4-b4e4-32a1c14e1b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file 'Jetpack drawing' as: https://generativelanguage.googleapis.com/v1beta/files/ui7oqyac3jl9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt with the uploaded image and text**"
      ],
      "metadata": {
        "id": "SpLaq4zR_i1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After uploading the file, you can make GenerateContent requests that reference the File API URI. Select the generative model and provide it with a text prompt and the uploaded image."
      ],
      "metadata": {
        "id": "3GiJ83Ab_1h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"Describe how this product might be manufactured.\"])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "BXU_AnV4-dqV",
        "outputId": "7aa5ba90-261f-4cf2-ea5b-274dbba180f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a breakdown of how the Jetpack Backpack, as conceptually designed, might be manufactured, keeping in mind that some aspects are highly speculative due to the lack of detailed specifications in the original image.\n\n**1. Backpack Shell:**\n\n* **Materials:**  Likely a durable, lightweight material like nylon or ripstop fabric.  This would need to be water-resistant or water-proof for weather protection.  For the internal structure, potentially a combination of reinforced plastics or lightweight metals for structural support.\n* **Manufacturing Process:**  The shell would likely be cut and sewn from the fabric, with potentially some sections being heat-sealed or welded for added durability. Internal frame components (if any) could be injection-molded or die-cast.\n\n**2.  Strap Support:**\n\n* **Materials:**  High-density foam padding covered in a durable fabric would be used for comfortable shoulder straps.\n* **Manufacturing Process:**  Foam is typically cut to shape, covered with fabric, and sewn to the backpack shell.\n\n**3.  USB-C Charging System:**\n\n* **Components:**  This would require a battery pack (possibly multiple smaller ones for weight distribution), charging circuitry, and a USB-C output port.\n* **Manufacturing Process:**  The battery pack would be assembled from individual cells or procured as a pre-built unit.  The circuitry would need to be carefully integrated, likely on a small printed circuit board (PCB), and securely housed within the backpack.  The port would be fixed to the external shell.\n\n**4.  Retractable Boosters:**\n\n* **This is the most challenging aspect to manufacture:** The image implies a steam-powered system.  Building a safe, lightweight, and efficient system for generating steam, controlling its release, and retracting the mechanism would be extremely complex.\n* **Potential Components:**  A miniature steam boiler (possibly using a rapid heating element), valves, pressure regulators, and a mechanism for retracting the nozzles.\n* **Manufacturing Process:**  This would involve precise machining of metal parts, specialized welding or brazing, and sophisticated control systems for regulating steam pressure and nozzle deployment.  Miniaturization is crucial for practical implementation.\n\n**5.  Laptop Compartment:**\n\n* **Materials:**  Padding for laptop protection and possibly a dedicated, rigid internal frame or shell for extra security.\n* **Manufacturing Process:**  Would involve cutting and sewing, with the padding materials attached to form the compartment within the larger backpack.\n\n**6.  Assembly:**\n\n*  Once all components are manufactured, the entire backpack would be assembled. This would likely involve skilled labor due to the complex integration of the different parts, especially the steam-powered system (if actually implemented).  Quality control would be a critical part of the process.\n\n**Challenges:**\n\n* **Steam System Miniaturization:**  Creating a safe, lightweight, and efficient steam-powered propulsion system is extremely difficult.\n* **Safety Regulations:**  A steam-powered backpack would require stringent safety certifications and testing to ensure it's not dangerous.\n* **Battery Life and Power:**  Achieving a 15-minute battery life for a steam-powered system would be a significant engineering challenge.\n* **Cost:**  The advanced engineering and precision manufacturing required would likely make the backpack very expensive.\n\nThe design, as presented, is highly imaginative, but translating it into a real product would face immense technical and logistical hurdles.  It's more likely a conceptual idea for now, than a readily manufacturable product.\n"
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Capabilties**"
      ],
      "metadata": {
        "id": "FgVIRkKSArxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section outlines specific vision capabilities of the Gemini model, including object detection and bounding box coordinates.\n",
        "\n"
      ],
      "metadata": {
        "id": "ogBY46KkBEiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Get bounding boxes**\n",
        "Gemini models are trained to return bounding box coordinates as relative widths or heights in the range of [0, 1]. These values are then scaled by 1000 and converted to integers. Effectively, the coordinates represent the bounding box on a 1000x1000 pixel version of the image. Therefore, you'll need to convert these coordinates back to the dimensions of your original image to accurately map the bounding boxes."
      ],
      "metadata": {
        "id": "Uw-sPrkUBG2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Create a prompt to detect bounding boxes.\n",
        "prompt = \"Return a bounding box for each of the objects in this image in [ymin, xmin, ymax, xmax] format.\"\n",
        "response = model.generate_content([sample_file_2, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "pKYiZ0rnAWnr",
        "outputId": "8d9972e4-1f65-4eef-eb47-02f79693f37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here are the bounding boxes for the objects in the image.  Note that some of the text is split across multiple lines, so the bounding boxes encompass the entire text phrase.  Accuracy is limited by the image resolution and OCR quality.\n\n* **Python, AI, Machine Learning Tutoring:** [274, 36, 402, 272]\n* **Machine Learning:** [145, 396, 204, 546]\n* **Supervised, Unsupervised, Reinforcement:** [212, 396, 246, 602]\n* **Deep Learning:** [145, 655, 204, 796]\n* **ANN, CNN, Computer Vision, PyTorch:** [212, 655, 272, 845]\n* **Data Visualization:** [359, 521, 418, 695]\n* **Python Programming:** [487, 350, 559, 511]\n* **Data Structures, OOP:** [561, 350, 584, 468]\n* **Data Science:** [593, 768, 653, 863]\n* **Predictive Analytics:** [656, 768, 691, 867]\n\n\nPlease note that the OCR had some errors (\"Unsupe\" instead of \"Unsupervised\", \"Camper Van\" instead of \"Computer Vision\").  The bounding boxes reflect the actual text as captured by the OCR.\n"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting with video**\n",
        "In this tutorial, you will upload a video using the File API and generate content based on those images."
      ],
      "metadata": {
        "id": "Wdr5aPswBju9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload a video file to the File API"
      ],
      "metadata": {
        "id": "_FQt2wNcI9bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXd_jqz6CDdF",
        "outputId": "f488109e-0d8e-4b49-8d28-cb20b8a5d63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-09 09:26:41--  https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.207, 173.194.210.207, 173.194.212.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238090979 (227M) [video/mp4]\n",
            "Saving to: ‘GreatRedSpot.mp4’\n",
            "\n",
            "GreatRedSpot.mp4    100%[===================>] 227.06M   155MB/s    in 1.5s    \n",
            "\n",
            "2025-02-09 09:26:42 (155 MB/s) - ‘GreatRedSpot.mp4’ saved [238090979/238090979]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the video to the File API and print the URI."
      ],
      "metadata": {
        "id": "HLwCriG9InlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_file_name = \"GreatRedSpot.mp4\"\n",
        "\n",
        "print(f\"Uploading file...\")\n",
        "video_file = genai.upload_file(path=video_file_name)\n",
        "print(f\"Completed upload: {video_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Epv-haCTgX",
        "outputId": "1a2fd5d3-83c7-4951-e397-c6cf938fa691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/s0siccetja03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RhQ7pvhiIVDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Verify file upload and check state**\n",
        "Verify the API has successfully received the files by calling the files.get method.\n",
        "\n",
        "NOTE: Video files have a State field in the File API. When a video is uploaded, it will be in the PROCESSING state until it is ready for inference. Only ACTIVE files can be used for model inference."
      ],
      "metadata": {
        "id": "NZkTQIDbIVG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Check whether the file is ready to be used.\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "    print('.', end='')\n",
        "    time.sleep(10)\n",
        "    video_file = genai.get_file(video_file.name)\n",
        "\n",
        "if video_file.state.name == \"FAILED\":\n",
        "  raise ValueError(video_file.state.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGrWYEpoCdZv",
        "outputId": "37a16f31-8df3-452f-913d-51b9674d8304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompt with a video and text**\n",
        "Once the uploaded video is in the ACTIVE state, you can make GenerateContent requests that specify the File API URI for that video. Select the generative model and provide it with the uploaded video and a text prompt."
      ],
      "metadata": {
        "id": "Ft9btp3dIErV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt.\n",
        "prompt = \"Summarize this video. Then create a quiz with answer key based on the information in the video.\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([video_file, prompt],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "\n",
        "# Print the response, rendering any Markdown\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "W-t5-CzGEVKm",
        "outputId": "eae263bd-645a-4f74-cfda-4a2cb01baf68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is a summary of the video, followed by a short quiz.\n\nThe video describes Jupiter's Great Red Spot, a gigantic, centuries-old storm.  Data from NASA missions, including Voyager, Hubble, and Juno, reveal that the storm is shrinking and becoming rounder. While scientists initially expected wind speeds within the spot to increase as it shrank (like a figure skater spinning faster when they pull in their arms), data show the storm is actually getting taller.  The Great Red Spot, once large enough to fit three Earths, is now only slightly larger than one.\n\n**Quiz:**\n\n1.  **True or False:** The Great Red Spot is a hurricane.\n2.  **What three NASA missions contributed data to this research?**\n3.  **What is the analogy used in the video to explain the initial expectation of what would happen to the storm?**\n4.  **What is actually happening to the Great Red Spot, according to the data?**\n5.  **How many Earths could fit inside the Great Red Spot today?**\n\n**Answer Key:**\n\n1.  False (It's an anticyclone)\n2. Voyager, Hubble, Juno\n3. A figure skater pulling in their arms to spin faster.\n4. It is getting taller.\n5. A little more than one."
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Refer to timestamps in the content**\n",
        "You can use timestamps of the form MM:SS to refer to specific moments in the video.\n",
        "\n"
      ],
      "metadata": {
        "id": "2e5kp5LtHoRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt.\n",
        "prompt = \"What are the examples given at 01:05 and 01:19 supposed to show us?\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([prompt, video_file],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "O4Xg72b5E9dB",
        "outputId": "3e0d8d6c-2194-44bb-f07b-119fc65ec81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's an explanation of what the examples at 01:05 and 01:19 are meant to show.\n\nAt **01:05**, the video shows a figure skater pulling in her arms while spinning. This is used as an analogy for the shrinking Great Red Spot.  As the skater brings her arms closer to her body, her spin increases due to the conservation of angular momentum. The expectation was that the Great Red Spot would behave similarly. As it shrinks, its rotation speed would increase.\n\nThe example at **01:19** shows a potter shaping a lump of clay on a spinning wheel. As the potter works the clay, it becomes taller and more narrow, but it doesn't spin faster. The video uses this to illustrate that the Great Red Spot, unlike the ice skater, is getting taller as it shrinks, not spinning faster."
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transcribe video and provide visual descriptions**\n",
        "The Gemini models can transcribe and provide visual descriptions of video content by processing both the audio track and visual frames. For visual descriptions, the model samples the video at a rate of 1 frame per second. This sampling rate may affect the level of detail in the descriptions, particularly for videos with rapidly changing visuals.\n",
        "\n",
        "\n",
        "[ ]\n"
      ],
      "metadata": {
        "id": "J8yncx05HWN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt.\n",
        "prompt = \"Transcribe the audio from this video, giving timestamps for salient events in the video. Also provide visual descriptions.\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([video_file, prompt],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "T1H9xxDYFeFx",
        "outputId": "6f4c2db0-7403-47e8-96d9-d5f0570047fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a transcription of the audio from the video, along with timestamps and visual descriptions.\n\n[00:00:00 to 00:00:15] The video opens with a dark space background speckled with stars. A partially illuminated planet Jupiter is in the center of the screen. The narrator begins to speak, \"Jupiter is the largest and oldest planet in our solar system. Its history spans 4.5 billion years. This gas giant is made of the same elements as a star, but it did not grow massive enough to ignite.\"\n\n[00:00:16 to 00:00:31] The camera focuses on the right half of Jupiter. The rings around Jupiter are visible. The narrator says, \"Jupiter's appearance is the result of its swirling interior of gases and liquids producing a tapestry of colorful cloud bands, as well as the iconic Great Red Spot.\"  The camera zooms in on the Great Red Spot.\n\n[00:00:32 to 00:00:44] The Great Red Spot is shown in more detail.  A smaller, darker, circular storm is also shown near the Great Red Spot. The narrator says, \"The Great Red Spot is a gigantic storm. It's an anticyclone, and with no land mass on the planet to slow it down, the Great Red Spot has raged for over a century.\"\n\n[00:00:45 to 00:01:04] The camera shows a view of Jupiter from a slightly different angle. The narrator says, \"But scientists studying the spot have noticed that it has been changing over time. The color is deepening, and it's actually shrinking and getting rounder. Those studying it expected to therefore see the wind speeds inside the Great Red Spot increasing as the storm shrinks.\"\n\n[00:01:05 to 00:01:11]  A black-and-white video clip of a figure ice skating is shown. The skater spins faster as she pulls her arms in. The narrator says, \"Like an ice skater who spins faster as she pulls in her arms. But this isn't the case.\"\n\n[00:01:12 to 00:01:24] The camera again focuses on the Great Red Spot. The narrator states, \"Data reveals the storm isn't spinning faster; it's actually getting taller. You can think of it like working with pottery. As the wide lump of clay spins, forces within are driving it taller.\"  A split-screen appears, showing a graph of the height of the Great Red Spot over time, and a video clip of someone working with clay on a pottery wheel.\n\n[00:01:25 to 00:01:35] The video returns to a view of Jupiter.  Images of the Great Red Spot from 1995, 2009, and 2015 are shown, highlighting its shrinking size.  The narrator comments, \"So, from our perspective looking down on the clouds, we see the spot getting smaller and rounder. The Great Red Spot used to be big enough to fit three Earths. Now it's just a little over one.\"  An image of Earth is superimposed on the Great Red Spot to illustrate the comparison.\n\n[00:01:36 to 00:01:46]  A 3D rendering of the Voyager spacecraft is shown approaching Jupiter. The narrator explains, \"These discoveries were made by analyzing data from numerous NASA missions, including Voyager, Hubble, and most recently, Juno.\"  Images of the Juno spacecraft are shown.\n\n[00:01:47 to 00:01:57] The video returns to the opening scene of Jupiter in space. The narrator says, \"And through more investigations, scientists hope to unlock more secrets of the mysterious Great Red Spot.\"  Close up images of the Great Red Spot are again shown.\n\n[00:01:58 to 00:02:06]  The video ends with a final shot of the Juno spacecraft, followed by the NASA Goddard Space Flight Center logo and website address."
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **List files**\n",
        "You can list all uploaded files and their URIs using files.list_files()."
      ],
      "metadata": {
        "id": "p5v4USdzHEPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files\n",
        "for file in genai.list_files():\n",
        "    print(f\"{file.display_name}, URI: {file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWznAAeeGZLe",
        "outputId": "396b556c-0629-4081-c684-a9c13576db73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GreatRedSpot.mp4, URI: https://generativelanguage.googleapis.com/v1beta/files/s0siccetja03\n",
            "Jetpack drawing, URI: https://generativelanguage.googleapis.com/v1beta/files/ui7oqyac3jl9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Delete files**\n",
        "Files are automatically deleted after 2 days. You can also manually delete them using files.delete()."
      ],
      "metadata": {
        "id": "ZeOIToFfGyXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.delete_file(video_file.name)\n",
        "print(f'Deleted file {video_file.uri}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aivySeo9GlAF",
        "outputId": "7c958153-7cae-4ad7-effd-4a45261c2c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted file https://generativelanguage.googleapis.com/v1beta/files/s0siccetja03\n"
          ]
        }
      ]
    }
  ]
}